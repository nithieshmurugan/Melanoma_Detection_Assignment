Abstract
Melanoma is the deadliest form of skin cancer among over 200 types. The diagnostic process begins with clinical screening, followed by dermoscopic analysis and histopathological examination. Early identification of melanoma greatly increases the chances of successful treatment. Initially, dermatologists perform a visual examination and capture dermatoscopic images of skin lesions using high-speed cameras, which achieve an accuracy of 65-80% without technical assistance. With further evaluation from specialists, this accuracy improves to 75-84%. This project aims to develop an automated classification system leveraging image processing techniques to accurately classify skin cancer based on images of skin lesions.

Problem Statement
The current skin biopsy process involves a dermatologist taking a sample of the lesion and examining it under a microscope, which can take over a week from the initial appointment to the biopsy report. This project seeks to reduce this timeframe to just a couple of days by implementing a predictive model. Using Convolutional Neural Networks (CNN), the system will classify nine types of skin cancer from images of outlier lesions. This reduction in diagnosis time has the potential to positively impact millions of individuals.

Dataset
The dataset consists of 2357 images of malignant and benign oncological diseases, which were formed from the International Skin Imaging Collaboration (ISIC). All images were sorted according to the classification taken with ISIC, and all subsets were divided into the same number of images, with the exception of melanomas and moles, whose images are slightly dominant. The data set contains the following diseases:

Actinic keratosis
Basal cell carcinoma
Dermatofibroma
Melanoma
Nevus
Pigmented benign keratosis
Seborrheic keratosis
Squamous cell carcinoma
Vascular lesion

CNN Architecture Design
To classify skin cancer using images of skin lesions, I developed a custom Convolutional Neural Network (CNN) model aimed at achieving higher accuracy in classification tasks.

Rescaling Layer: This layer rescales input values from the range [0, 255] to [0, 1].

Convolutional Layer: Convolutional layers perform a convolution operation on the input, transforming the pixels within a receptive field into a single value. This process decreases the image size while consolidating information into a single pixel.

Pooling Layer: Pooling layers reduce the dimensions of the feature maps, decreasing the number of parameters and computational load. They summarize the features within a specified region of the feature map generated by the convolutional layer.

Dropout Layer: The Dropout layer randomly sets a fraction of input units to zero during training, which helps prevent overfitting.

Flatten Layer: Flattening converts multi-dimensional data into a one-dimensional array for input into the next layer. The output of the convolutional layers is flattened into a long feature vector connected to the fully connected layer.

Dense Layer: The dense layer is fully connected, meaning each neuron receives input from all neurons in the previous layer.

Activation Function (ReLU): The Rectified Linear Unit (ReLU) activation function outputs the input directly if positive; otherwise, it outputs zero. ReLU helps overcome the vanishing gradient problem, allowing models to learn faster and perform better.

Activation Function (Softmax): The Softmax function is used in the output layer of neural network models that predict a multinomial probability distribution. Its primary advantage is that it outputs probabilities ranging from 0 to 1, with the sum of all probabilities equal to one.